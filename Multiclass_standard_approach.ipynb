{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP - standard approach.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/z3193631/NLP_Demo/blob/master/Multiclass_standard_approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zvajfrh3k2O",
        "colab_type": "text"
      },
      "source": [
        "# Bag of Words Approach and Logistic Regression for NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xf-ywkZBq-SE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd, numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywg0dDGku2t9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train_sample.csv')\n",
        "vals = pd.read_csv('val_sample.csv')\n",
        "test = pd.read_csv('test.csv.zip')\n",
        "test_label = pd.read_csv('test_labels.csv.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwsg6r2w2a5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nZmI8I_w6gC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "join_test = pd.merge(test,test_label, how='inner')\n",
        "final_test = join_test[join_test.ne(-1).all(axis=1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L-m37EtxtnT",
        "colab_type": "code",
        "outputId": "17defcc2-5471-4590-96f6-b777c6ee49e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "lens = train.comment_text.str.len()\n",
        "lens.mean(), lens.std(), lens.max()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(385.188, 579.9463720469764, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mjhSJ-zyF0y",
        "colab_type": "code",
        "outputId": "3be2fa62-0aec-40cd-8978-1dda107e4713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "lens.hist()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6f74fde9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFY5JREFUeJzt3W2MXNV9x/Hvr16eYqf4ATKy1lbX\nUaxEtG6IsyJGRNGAmxQ7UewXBBlZYUNdbdWSNCmWgmmkRpH6AqoSAlJFsorTmCjBEBJki9AkruGq\n8guc2GDMg0O9EBN7a+yE2KZjlLZ2/n0xx2TYGPbOzuwMe+b3kUZz7rnnzj3/0fDz5czDKiIwM7N8\n/UG3J2BmZlPLQW9mljkHvZlZ5hz0ZmaZc9CbmWXOQW9mljkHvZlZ5hz0ZmaZc9CbmWWur9sTALjo\nootiYGCg6eNOnjzJzJkz2z+ht7BerBl6s27X3BtaqXn37t2/ioiLJxr3lgj6gYEBdu3a1fRxRVFQ\nrVbbP6G3sF6sGXqzbtfcG1qpWdKLZcZ56cbMLHMOejOzzDnozcwy56A3M8tcqaCX9HeSnpH0tKR7\nJZ0vaZGknZJGJd0n6dw09ry0PZr2D0xlAWZm9uYmDHpJ/cDfAoMR8SfADGANcBtwR0S8CzgGrEuH\nrAOOpf470jgzM+uSsks3fcAFkvqAtwGHgauAB9L+TcDq1F6Vtkn7l0tSe6ZrZmbNmjDoI2IM+Gfg\nF9QD/gSwGzgeEafSsENAf2r3AwfTsafS+HntnbaZmZU14RemJM2hfpW+CDgOfBe4utUTSxoGhgEq\nlQpFUTT9GLVabVLHTWe9WDP0Zt2uuTd0ouYy34z9M+DnEfFLAEnfB64AZkvqS1ftC4CxNH4MWAgc\nSks9FwIvj3/QiBgBRgAGBwdjMt8MK4qCT/3wZNPHtcuBWz/a8XP24jcHoTfrds29oRM1l1mj/wWw\nTNLb0lr7cuBZ4FHgmjRmCNiS2lvTNmn/IxER7ZuymZk1o8wa/U7qb6o+DjyVjhkBbgZukjRKfQ1+\nYzpkIzAv9d8EbJiCeZuZWUmlftQsIr4IfHFc9wvAZWcZ+xvgE61PzczM2sHfjDUzy5yD3swscw56\nM7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD\n3swscw56M7PMOejNzDLnoDczy9yEQS/p3ZL2NNxekfQ5SXMlbZO0P93PSeMl6S5Jo5L2Slo69WWY\nmdkbKfM3Y5+LiEsj4lLg/cCrwIPU/xbs9ohYDGznd38bdgWwON2GgbunYuJmZlZOs0s3y4HnI+JF\nYBWwKfVvAlan9irgnqh7DJgtaX5bZmtmZk1rNujXAPemdiUiDqf2S0AltfuBgw3HHEp9ZmbWBYqI\ncgOlc4H/Av44Io5IOh4Rsxv2H4uIOZIeAm6NiB2pfztwc0TsGvd4w9SXdqhUKu/fvHlz05Ov1Wr8\n/MTppo9rlyX9F3b8nLVajVmzZnX8vN3Wi3W75t7QSs1XXnnl7ogYnGhcXxOPuQJ4PCKOpO0jkuZH\nxOG0NHM09Y8BCxuOW5D6XiciRoARgMHBwahWq01Mpa4oCm7fcbLp49rlwNpqx89ZFAWTea6mu16s\n2zX3hk7U3MzSzXX8btkGYCswlNpDwJaG/uvTp2+WAScalnjMzKzDSl3RS5oJfBj4q4buW4H7Ja0D\nXgSuTf0PAyuBUeqf0LmhbbM1M7OmlQr6iDgJzBvX9zL1T+GMHxvAjW2ZnZmZtczfjDUzy5yD3sws\ncw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDczy5yD3swscw56M7PMOejNzDLnoDcz\ny5yD3swscw56M7PMOejNzDLnoDczy1ypoJc0W9IDkn4maZ+kyyXNlbRN0v50PyeNlaS7JI1K2itp\n6dSWYGZmb6bsFf2dwA8j4j3Ae4F9wAZge0QsBranbYAVwOJ0GwbubuuMzcysKRMGvaQLgQ8BGwEi\n4n8j4jiwCtiUhm0CVqf2KuCeqHsMmC1pfttnbmZmpZS5ol8E/BL4V0lPSPq6pJlAJSIOpzEvAZXU\n7gcONhx/KPWZmVkXKCLefIA0CDwGXBEROyXdCbwCfCYiZjeMOxYRcyQ9BNwaETtS/3bg5ojYNe5x\nh6kv7VCpVN6/efPmpidfq9X4+YnTTR/XLkv6L+z4OWu1GrNmzer4ebutF+t2zb2hlZqvvPLK3REx\nONG4vhKPdQg4FBE70/YD1Nfjj0iaHxGH09LM0bR/DFjYcPyC1Pc6ETECjAAMDg5GtVotMZXXK4qC\n23ecbPq4djmwttrxcxZFwWSeq+muF+t2zb2hEzVPuHQTES8BByW9O3UtB54FtgJDqW8I2JLaW4Hr\n06dvlgEnGpZ4zMysw8pc0QN8Bvi2pHOBF4AbqP8jcb+kdcCLwLVp7MPASmAUeDWNNTOzLikV9BGx\nBzjbOtDys4wN4MYW52VmZm3ib8aamWXOQW9mljkHvZlZ5hz0ZmaZc9CbmWXOQW9mljkHvZlZ5hz0\nZmaZc9CbmWXOQW9mljkHvZlZ5hz0ZmaZc9CbmWXOQW9mljkHvZlZ5hz0ZmaZc9CbmWWuVNBLOiDp\nKUl7JO1KfXMlbZO0P93PSf2SdJekUUl7JS2dygLMzOzNNXNFf2VEXBoRZ/6k4AZge0QsBranbYAV\nwOJ0Gwbubtdkzcysea0s3awCNqX2JmB1Q/89UfcYMFvS/BbOY2ZmLSgb9AH8WNJuScOprxIRh1P7\nJaCS2v3AwYZjD6U+MzPrgr6S4z4YEWOS3gFsk/Szxp0REZKimROnfzCGASqVCkVRNHM4ALVajfVL\nTjd9XLtMZs6tqtVqXTlvt/Vi3a65N3Si5lJBHxFj6f6opAeBy4AjkuZHxOG0NHM0DR8DFjYcviD1\njX/MEWAEYHBwMKrVatOTL4qC23ecbPq4djmwttrxcxZFwWSeq+muF+t2zb2hEzVPuHQjaaakt59p\nAx8Bnga2AkNp2BCwJbW3AtenT98sA040LPGYmVmHlbmirwAPSjoz/jsR8UNJPwXul7QOeBG4No1/\nGFgJjAKvAje0fdZmZlbahEEfES8A7z1L/8vA8rP0B3BjW2ZnZmYt8zdjzcwy56A3M8ucg97MLHMO\nejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8uc\ng97MLHMOejOzzDnozcwyVzroJc2Q9ISkh9L2Ikk7JY1Kuk/Suan/vLQ9mvYPTM3UzcysjGau6D8L\n7GvYvg24IyLeBRwD1qX+dcCx1H9HGmdmZl1SKuglLQA+Cnw9bQu4CnggDdkErE7tVWmbtH95Gm9m\nZl1Q9or+K8Dngd+m7XnA8Yg4lbYPAf2p3Q8cBEj7T6TxZmbWBX0TDZD0MeBoROyWVG3XiSUNA8MA\nlUqFoiiafoxarcb6JafbNaWmTWbOrarVal05b7f1Yt2uuTd0ouYJgx64Avi4pJXA+cAfAncCsyX1\npav2BcBYGj8GLAQOSeoDLgReHv+gETECjAAMDg5GtVptevJFUXD7jpNNH9cuB9ZWO37OoiiYzHM1\n3fVi3a65N3Si5gmXbiLilohYEBEDwBrgkYhYCzwKXJOGDQFbUntr2ibtfyQioq2zNjOz0lr5HP3N\nwE2SRqmvwW9M/RuBean/JmBDa1M0M7NWlFm6eU1EFECR2i8Al51lzG+AT7RhbmZm1gb+ZqyZWeYc\n9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQm5llzkFvZpY5\nB72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYmDHpJ50v6iaQnJT0j6Uupf5GknZJGJd0n6dzUf17a\nHk37B6a2BDMzezNlruj/B7gqIt4LXApcLWkZcBtwR0S8CzgGrEvj1wHHUv8daZyZmXXJhEEfdbW0\neU66BXAV8EDq3wSsTu1VaZu0f7kktW3GZmbWlFJr9JJmSNoDHAW2Ac8DxyPiVBpyCOhP7X7gIEDa\nfwKY185Jm5lZeX1lBkXEaeBSSbOBB4H3tHpiScPAMEClUqEoiqYfo1arsX7J6VanMmmTmXOrarVa\nV87bbb1Yt2vuDZ2ouVTQnxERxyU9ClwOzJbUl67aFwBjadgYsBA4JKkPuBB4+SyPNQKMAAwODka1\nWm168kVRcPuOk00f1y4H1lY7fs6iKJjMczXd9WLdrrk3dKLmMp+6uThdySPpAuDDwD7gUeCaNGwI\n2JLaW9M2af8jERHtnLSZmZVX5op+PrBJ0gzq/zDcHxEPSXoW2CzpH4EngI1p/EbgW5JGgV8Da6Zg\n3mZmVtKEQR8Re4H3naX/BeCys/T/BvhEW2ZnZmYt8zdjzcwy56A3M8ucg97MLHMOejOzzDnozcwy\n56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOz\nzDnozcwyV+Zvxi6U9KikZyU9I+mzqX+upG2S9qf7Oalfku6SNCppr6SlU12EmZm9sTJX9KeA9RFx\nCbAMuFHSJcAGYHtELAa2p22AFcDidBsG7m77rM3MrLQJgz4iDkfE46n938A+oB9YBWxKwzYBq1N7\nFXBP1D0GzJY0v+0zNzOzUppao5c0QP0Phe8EKhFxOO16Caikdj9wsOGwQ6nPzMy6oK/sQEmzgO8B\nn4uIVyS9ti8iQlI0c2JJw9SXdqhUKhRF0czhANRqNdYvOd30ce0ymTm3qlardeW83daLdbvm3tCJ\nmksFvaRzqIf8tyPi+6n7iKT5EXE4Lc0cTf1jwMKGwxekvteJiBFgBGBwcDCq1WrTky+Kgtt3nGz6\nuHY5sLba8XMWRcFknqvprhfrds29oRM1l/nUjYCNwL6I+HLDrq3AUGoPAVsa+q9Pn75ZBpxoWOIx\nM7MOK3NFfwXwSeApSXtS398DtwL3S1oHvAhcm/Y9DKwERoFXgRvaOmMzM2vKhEEfETsAvcHu5WcZ\nH8CNLc7LzMzaxN+MNTPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPL\nnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8yV/pux9vsGNvyg4+dcv+QU1Y6f1cymM1/R\nm5llrszfjP2GpKOSnm7omytpm6T96X5O6pekuySNStoraelUTt7MzCZW5or+m8DV4/o2ANsjYjGw\nPW0DrAAWp9swcHd7pmlmZpM1YdBHxH8Avx7XvQrYlNqbgNUN/fdE3WPAbEnz2zVZMzNr3mTX6CsR\ncTi1XwIqqd0PHGwYdyj1mZlZl7T8qZuICEnR7HGShqkv71CpVCiKoulz12o11i853fRx01nlAib1\nXE13tVqt5+p2zb2hEzVPNuiPSJofEYfT0szR1D8GLGwYtyD1/Z6IGAFGAAYHB6NarTY9iaIouH3H\nyaaPm87WLznFtZN4rqa7oiiYzGtkOnPNvaETNU926WYrMJTaQ8CWhv7r06dvlgEnGpZ4zMysCya8\nopd0L1AFLpJ0CPgicCtwv6R1wIvAtWn4w8BKYBR4FbhhCuZsZmZNmDDoI+K6N9i1/CxjA7ix1UmZ\nmVn7+JuxZmaZc9CbmWXOQW9mljkHvZlZ5hz0ZmaZc9CbmWXOQW9mljkHvZlZ5hz0ZmaZc9CbmWXO\nQW9mlrmWf4/eOm9gww+6du4Dt360a+c2s8nxFb2ZWeYc9GZmmXPQm5llzkFvZpY5vxlrTenWG8Hf\nvHpmV85rloMpuaKXdLWk5ySNStowFecwM7Ny2h70kmYA/wKsAC4BrpN0SbvPY2Zm5UzF0s1lwGhE\nvAAgaTOwCnh2Cs5lPeKpsRN8qgvLRv7eQG/o5ndTOrEsORVB3w8cbNg+BHxgCs5jNuW6GQDrl5zq\nyj9u3eT3YqaGIqK9DyhdA1wdEX+Ztj8JfCAiPj1u3DAwnDbfDTw3idNdBPyqhelOR71YM/Rm3a65\nN7RS8x9FxMUTDZqKK/oxYGHD9oLU9zoRMQKMtHIiSbsiYrCVx5huerFm6M26XXNv6ETNU/Gpm58C\niyUtknQusAbYOgXnMTOzEtp+RR8RpyR9GvgRMAP4RkQ80+7zmJlZOVPyhamIeBh4eCoee5yWln6m\nqV6sGXqzbtfcG6a85ra/GWtmZm8t/q0bM7PMTdugz+lnFiR9Q9JRSU839M2VtE3S/nQ/J/VL0l2p\n7r2SljYcM5TG75c01I1aypK0UNKjkp6V9Iykz6b+bOuWdL6kn0h6MtX8pdS/SNLOVNt96UMMSDov\nbY+m/QMNj3VL6n9O0p93p6LyJM2Q9ISkh9J21jVLOiDpKUl7JO1Kfd17bUfEtLtRf5P3eeCdwLnA\nk8Al3Z5XC/V8CFgKPN3Q90/AhtTeANyW2iuBfwMELAN2pv65wAvpfk5qz+l2bW9S83xgaWq/HfhP\n6j+ZkW3dae6zUvscYGeq5X5gTer/KvDXqf03wFdTew1wX2pfkl7z5wGL0n8LM7pd3wS13wR8B3go\nbWddM3AAuGhcX9de211/Qib5JF4O/Khh+xbglm7Pq8WaBsYF/XPA/NSeDzyX2l8Drhs/DrgO+FpD\n/+vGvdVvwBbgw71SN/A24HHq3xr/FdCX+l97bVP/5Nrlqd2Xxmn8671x3FvxRv27NNuBq4CHUg25\n13y2oO/aa3u6Lt2c7WcW+rs0l6lSiYjDqf0SUEntN6p92j4n6X/P30f9CjfrutMSxh7gKLCN+pXp\n8Yg4lYY0zv+12tL+E8A8plnNwFeAzwO/TdvzyL/mAH4saXf6FQDo4mvbv0c/DURESMry41GSZgHf\nAz4XEa9Iem1fjnVHxGngUkmzgQeB93R5SlNK0seAoxGxW1K12/PpoA9GxJikdwDbJP2scWenX9vT\n9Yq+1M8sTHNHJM0HSPdHU/8b1T7tnhNJ51AP+W9HxPdTd/Z1A0TEceBR6ssWsyWduehqnP9rtaX9\nFwIvM71qvgL4uKQDwGbqyzd3knfNRMRYuj9K/R/0y+jia3u6Bn0v/MzCVuDMu+xD1Newz/Rfn96p\nXwacSP87+CPgI5LmpHfzP5L63pJUv3TfCOyLiC837Mq2bkkXpyt5JF1A/T2JfdQD/5o0bHzNZ56L\na4BHor5YuxVYkz6hsghYDPykM1U0JyJuiYgFETFA/b/TRyJiLRnXLGmmpLefaVN/TT5NN1/b3X7T\nooU3O1ZS/6TG88AXuj2fFmu5FzgM/B/1dbh11NcltwP7gX8H5qaxov6HXZ4HngIGGx7nL4DRdLuh\n23VNUPMHqa9j7gX2pNvKnOsG/hR4ItX8NPAPqf+d1ENrFPgucF7qPz9tj6b972x4rC+k5+I5YEW3\naytZf5Xffeom25pTbU+m2zNn8qmbr21/M9bMLHPTdenGzMxKctCbmWXOQW9mljkHvZlZ5hz0ZmaZ\nc9CbmWXOQW9mljkHvZlZ5v4fAqVjukSp1JQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y25pRBxKyWIp",
        "colab_type": "code",
        "outputId": "2d991806-2c36-4227-c1b6-fc913179bc04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "train['none'] = 1-train[label_cols].max(axis=1)\n",
        "train.describe()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>none</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.00000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.092000</td>\n",
              "      <td>0.01200</td>\n",
              "      <td>0.048000</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.048000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>0.902000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.289171</td>\n",
              "      <td>0.10894</td>\n",
              "      <td>0.213873</td>\n",
              "      <td>0.070569</td>\n",
              "      <td>0.213873</td>\n",
              "      <td>0.099549</td>\n",
              "      <td>0.297463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             toxic  severe_toxic  ...  identity_hate         none\n",
              "count  1000.000000    1000.00000  ...    1000.000000  1000.000000\n",
              "mean      0.092000       0.01200  ...       0.010000     0.902000\n",
              "std       0.289171       0.10894  ...       0.099549     0.297463\n",
              "min       0.000000       0.00000  ...       0.000000     0.000000\n",
              "25%       0.000000       0.00000  ...       0.000000     1.000000\n",
              "50%       0.000000       0.00000  ...       0.000000     1.000000\n",
              "75%       0.000000       0.00000  ...       0.000000     1.000000\n",
              "max       1.000000       1.00000  ...       1.000000     1.000000\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrX22nVH0uWq",
        "colab_type": "code",
        "outputId": "fdb263b0-6170-4425-a71f-cbae99ea719a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train),len(test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 153164)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIL9CmiZ0w39",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#making sure column is not empty\n",
        "COMMENT = 'comment_text'\n",
        "train[COMMENT].fillna(\"unknown\", inplace=True)\n",
        "test[COMMENT].fillna(\"unknown\", inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F75WW_cN3blH",
        "colab_type": "text"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0qE_x863UYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##create ngrams\n",
        "# import re, string\n",
        "# re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
        "\n",
        "# def tokenize(s): return re_tok.sub(r' \\1 ', s).split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyBo2dP15NOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #This creates a sparse matrix with only a small number of non-zero elements (stored elements in the representation below).\n",
        "# n = train.shape[0]\n",
        "# vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
        "#                min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
        "#                smooth_idf=1, sublinear_tf=1 )\n",
        "# trn_term_doc = vec.fit_transform(train[COMMENT])\n",
        "# test_term_doc = vec.transform(test[COMMENT])\n",
        "\n",
        "# trn_term_doc, test_term_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwYa2hXC5fJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #naive bayes formula\n",
        "# def pr(y_i, y):\n",
        "#     p = x[y==y_i].sum(0)\n",
        "#     return (p+1) / ((y==y_i).sum()+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYzoxm1h6Nw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = trn_term_doc\n",
        "# test_x = test_term_doc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btNC98SQ6y3k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #abstraction for the model steps\n",
        "\n",
        "# def get_mdl(y):\n",
        "#     y = y.values\n",
        "#     r = np.log(pr(1,y) / pr(0,y))\n",
        "#     m = LogisticRegression(C=4, dual=True)\n",
        "#     x_nb = x.multiply(r)\n",
        "#     return m.fit(x_nb, y), r\n",
        "  \n",
        "# #fit one model for each dependent variable\n",
        "# preds = np.zeros((len(test), len(label_cols)))\n",
        "\n",
        "# for i, j in enumerate(label_cols):\n",
        "#     print('fit', j)\n",
        "#     m,r = get_mdl(train[j])\n",
        "#     preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]\n",
        "    \n",
        "#     pred_test = m.predict_proba(test_x.multiply(r))[:,1]\n",
        "#     print('ROC AUC:', roc_auc_score(test_label[j], pred_test))\n",
        "#     loss.append(roc_auc_score(test_label[j], pred_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpxufS2Y9maE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df = pd.concat([train['comment_text'], vals['comment_text']], axis=0)\n",
        "# df = df.fillna(\"unknown\")\n",
        "\n",
        "# nrow_train = train.shape[0]\n",
        "\n",
        "# vectorizer = TfidfVectorizer(stop_words='english', max_features=50000)\n",
        "# X = vectorizer.fit_transform(df)\n",
        "\n",
        "# col = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "# preds = np.zeros((train.shape[0], len(col)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YMU6lihJeBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = train['comment_text']\n",
        "df = df.fillna(\"unknown\")\n",
        "\n",
        "nrow_train = train.shape[0]\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words='english', max_features=50000)\n",
        "X = vectorizer.fit_transform(df)\n",
        "\n",
        "col = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
        "\n",
        "preds = np.zeros((train.shape[0], len(col)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_3ahKl5JfMx",
        "colab_type": "code",
        "outputId": "984f81a7-d353-4d22-dd03-4ff029e1c77f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "loss = []\n",
        "\n",
        "Y = vectorizer.transform(final_test['comment_text']) #for test dataset validation\n",
        "\n",
        "for i, j in enumerate(col):\n",
        "    print('===Fit '+j)\n",
        "    model = LogisticRegression(penalty='l2')\n",
        "    model.fit(X, train[j])\n",
        "    preds[:,i] = model.predict_proba(X)[:,1]\n",
        "    \n",
        "    pred_train = model.predict_proba(X)[:,1]\n",
        "    pred_test = model.predict_proba(Y)[:,1]\n",
        "    print('ROC AUC:', roc_auc_score(final_test[j], pred_test))\n",
        "    loss.append(roc_auc_score(final_test[j], pred_test))\n",
        "    \n",
        "print('mean column-wise ROC AUC:', np.mean(loss))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===Fit toxic\n",
            "ROC AUC: 0.8976874019679926\n",
            "===Fit severe_toxic\n",
            "ROC AUC: 0.9489800853167608\n",
            "===Fit obscene\n",
            "ROC AUC: 0.9236615106993161\n",
            "===Fit threat\n",
            "ROC AUC: 0.9246947770530405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "===Fit insult\n",
            "ROC AUC: 0.8918130552450203\n",
            "===Fit identity_hate\n",
            "ROC AUC: 0.8867149052671137\n",
            "mean column-wise ROC AUC: 0.9122586225915406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKMMEal8BZ_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}